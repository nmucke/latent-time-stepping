dataset_args:
  input_seq_len: 16
  output_seq_len: 64
  num_time_steps: 600

dataloader_args:
  batch_size: 512
  shuffle: True
  num_workers: 8
  
model_args:
  parameter_encoder_args: 
    embed_dim: 16
    num_heads: 2
    embed_hidden_dim: 32
    num_layers: 2
    pars_dim: 2
  time_stepping_decoder:
    latent_dim: 4
    embed_dim: 16
    num_heads: 2
    embed_hidden_dim: 32
    num_layers: 2
    input_seq_len: 16
    output_seq_len: 64

optimizer_args:
  learning_rate: 5.0e-4
  weight_decay: 1.0e-10
  scheduler_args:
    warmup: 50
    max_iters: 1000

train_stepper_args:
  teacher_forcing_ratio: 0.0
  teacher_forcing_ratio_reduction: 0.9
  teacher_forcing_ratio_reduction_freq: 50
  mixed_precision: False

train_args:
  num_epochs: 1000
  patience: 100

