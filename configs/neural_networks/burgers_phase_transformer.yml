dataset_args:
  input_seq_len: 8
  output_seq_len: 64
  num_time_steps: 300
  with_pars: False

dataloader_args:
  batch_size: 256
  shuffle: True
  num_workers: 4
  
model_args:
  parameter_encoder_args: null
  time_stepping_decoder:
    latent_dim: 8
    embed_dim: 32
    num_heads: 2
    embed_hidden_dim: 32
    num_layers: 3
    input_seq_len: 8
    output_seq_len: 128

optimizer_args:
  learning_rate: 5.0e-4
  weight_decay: 1.0e-8
  scheduler_args:
    warmup: 25
    max_iters: 1000

train_stepper_args:
  teacher_forcing_ratio: 0.0
  teacher_forcing_ratio_reduction: 0.7
  teacher_forcing_ratio_reduction_freq: 5000
  mixed_precision: False

train_args:
  num_epochs: 1000
  patience: 50

